{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "246dcb35-a0f2-4ce2-a46e-f6b8c1053bf2",
   "metadata": {},
   "source": [
    "# M03. Predict Pulls\n",
    "- Predict when pitcher gets removed from the game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4534de56-4550-4dce-99fc-73d526095998",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"U1. Imports.ipynb\"\n",
    "%run \"U2. Utilities.ipynb\"\n",
    "%run \"U3. Classes.ipynb\"\n",
    "%run \"D3. Simulation Functions.ipynb\"\n",
    "\n",
    "baseball_path = r'C:\\Users\\james\\Documents\\MLB\\Database'\n",
    "\n",
    "db_path = r'C:\\Users\\james\\Documents\\MLB\\Database\\MLBDB.db'\n",
    "engine = create_engine(f'sqlite:///{db_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d007683e-abe8-4fa1-bc35-8ecdd3ee63b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import log_loss, classification_report, f1_score, make_scorer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from tensorflow import keras\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ff8569-0a21-4440-888e-7bf33c4821da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b329e039-ddf8-46ac-ade2-bcd519279b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"A03. Steamer.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a6014a-eb27-4083-9537-1ec7e127de15",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfe2881-7c98-44ec-99de-aae0a9a9df31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the last instance of each player in each game, assuming they have enough PAs\n",
    "sql_query = f'''\n",
    "    SELECT *\n",
    "    FROM \"Dataset\"\n",
    "'''\n",
    "\n",
    "complete_dataset = pd.read_sql_query(sql_query, con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9151f66-c2ce-407e-a373-5b4fffcf24e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31af98da-c1d1-43f0-a38d-7992b6b96f0a",
   "metadata": {},
   "source": [
    "### Steamer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd7e3e9-972d-4767-a793-57c48e6aac6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the last instance of each player in each game, assuming they have enough PAs\n",
    "sql_query = f'''\n",
    "  SELECT *\n",
    "  FROM \"Steamer Pitchers\"\n",
    "'''\n",
    "\n",
    "steamer_pitchers_df = pd.read_sql_query(sql_query, con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc05c0e-a762-4dd1-b624-0a3eef35f58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean\n",
    "steamer_pitchers_df2 = clean_steamer_pitchers(steamer_pitchers_df)\n",
    "steamer_pitchers_df2.dropna(subset=pitcher_stats_fg2, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7eb40c5-3686-4b70-8a46-c35f58b9c1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "steamer_pitchers_df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c115569b-2eb1-4689-976b-2bec2de41de2",
   "metadata": {},
   "source": [
    "### Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74aac58-6b72-4d70-992a-234693ddd528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the dates of Steamer projections\n",
    "# We'll take the most recent and merge in that projection for each player\n",
    "pitcher_steamer_dates = list(steamer_pitchers_df2['date'].unique())\n",
    "\n",
    "# Define a function to find the largest number in \"steamer_dates\" less than or equal to a given \"date\"\n",
    "def find_steamer_date(date, steamer_dates):\n",
    "    max_steamer_date = max(filter(lambda d: d <= date, steamer_dates), default=None)\n",
    "    return max_steamer_date\n",
    "\n",
    "# Apply the function to create the \"steamer_date\" column in your DataFrame\n",
    "complete_dataset[\"pitcher_date\"] = complete_dataset[\"date\"].apply(lambda x: find_steamer_date(x, pitcher_steamer_dates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de79d10-e324-4580-be44-eb38ba412b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge\n",
    "complete_merged_df = pd.merge(complete_dataset, steamer_pitchers_df2[['mlbamid', 'date'] + pitcher_stats_fg2] , left_on=['pitcher', 'pitcher_date'], right_on=['mlbamid', 'date'], how='left', suffixes=(\"\", \"_fg\"))\n",
    "complete_merged_df.drop_duplicates(subset=['date', 'gamePk', 'atBatIndex'], keep='last', inplace=True)\n",
    "complete_merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a29430c-a6e3-42c1-8b8d-a567dfc91024",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_dataset(df): \n",
    "    # Calculate scores bot batter and pitcher teams\n",
    "    df['pitcher_score'] = np.where(df['halfInning'] == \"top\", df['homeScore'], df['awayScore'])\n",
    "    df['batter_score'] = np.where(df['halfInning'] == \"top\", df['awayScore'], df['homeScore'])\n",
    "    \n",
    "    # Number of batters faced (will be used to calculate rolling sum)\n",
    "    df['faced'] = 1\n",
    "    \n",
    "    # Convert to numeric\n",
    "    df['rbi'] = df['rbi'].astype('int')\n",
    "    \n",
    "    # Determine year\n",
    "    df['year'] = df['date'].astype('str').str[:4]\n",
    "    \n",
    "    # Cumulative counts\n",
    "    # Stats to sum\n",
    "    sums_list = ['gamePk', 'pitcher'] + events_list + ['rbi', 'faced']\n",
    "    # Calculate\n",
    "    sums = df[sums_list].groupby(['gamePk', 'pitcher']).cumsum()\n",
    "    # Add suffix\n",
    "    sums = sums.add_suffix(\"_sum\")\n",
    "    \n",
    "    # Add rolling sums\n",
    "    df = pd.concat([df, sums], axis=1)\n",
    "    \n",
    "    # Identify if it's the bottom of the inning (a little more helpful than \"top\" as it's sortable)\n",
    "    df['bottom'] = (df['top'] == 0).astype('int')\n",
    "    \n",
    "    # Sort to identify starting pitchers\n",
    "    df = df.sort_values(by=['date', 'gamePk', 'bottom', 'atBatIndex'])\n",
    "    \n",
    "    # The starter has the lowest atBatIndex\n",
    "    df['atBatIndex_min'] = df.groupby(['gamePk', 'bottom'])['atBatIndex'].transform('min')\n",
    "    df['start'] = (df['atBatIndex'] == df['atBatIndex_min']).astype('int')\n",
    "        \n",
    "    # Identify starter throughout\n",
    "    df['starter'] = df.groupby(['pitcher', 'gamePk'])['start'].cumsum()\n",
    "    \n",
    "    # Keep only starters\n",
    "    df = df.query('starter == 1')\n",
    "    \n",
    "    # The starter is pulled at their highest atBatIndex\n",
    "    df['atBatIndex_max'] = df.groupby(['gamePk', 'bottom'])['atBatIndex'].transform('max')\n",
    "    df['pulled'] = (df['atBatIndex'] == df['atBatIndex_max']).astype('int')\n",
    "    \n",
    "    # Rolling sums stats (post-rolling sum)\n",
    "    rolled_sums_list = [f'{stat}_sum' for stat in events_list] + ['rbi_sum', 'faced_sum']\n",
    "    # Variables to keep\n",
    "    keep_list = ['date', 'year', 'gamePk', 'pitcher', 'pitcherName', 'batter', 'batterName', 'atBatIndex', 'pitcher_score', 'batter_score'] + pull_inputs + pitcher_stats_fg2 + rolled_sums_list + ['start', 'pulled']\n",
    "    \n",
    "    # Keep relevant variables\n",
    "    df = df[keep_list]\n",
    "    \n",
    "    # Drop if we don't have Steamer\n",
    "    df.dropna(subset=pitcher_stats_fg2, inplace=True)\n",
    "    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193ef1f8-1fa1-4136-a015-7a6ad6fcb2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "pulls_dataset = pull_dataset(complete_merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864dd8bb-558f-4b27-bf3f-2543cf735f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pitchers\n",
    "with open(os.path.join(model_path, \"pitcher_stats_fg_scaler_20231027.pkl\"), \"rb\") as file:\n",
    "    pitcher_stats_fg_scaler = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1fe345-2ec7-4349-a90e-efa6d86598a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pulls_dataset[pitcher_stats_fg] = pitcher_stats_fg_scaler.fit_transform(pulls_dataset[pitcher_stats_fg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc38b23-c373-4fa7-9a09-8f95ede5cf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full dataset\n",
    "X = pulls_dataset[pull_inputs3]\n",
    "y = pulls_dataset['pulled']\n",
    "\n",
    "# Split into training and testing groups\n",
    "X_train = pulls_dataset.groupby(pulls_dataset['year']).apply(lambda x: x.head(int(len(x)*2/3)))\n",
    "X_test = pulls_dataset.groupby(pulls_dataset['year']).apply(lambda x: x.tail(int(len(x)*1/3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e8f177-8a6b-4bcc-a119-2862cd6c70e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e904ea-b243-40f1-a94a-a0494ccf1156",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7ddb37c-4952-4f64-8adf-2041ee2d1fb4",
   "metadata": {},
   "source": [
    "### Train Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477bd072-5b6a-4fd0-a1e8-a6684523b347",
   "metadata": {},
   "source": [
    "##### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a191091-9148-4aa5-8d4f-0ab347592f7b",
   "metadata": {},
   "source": [
    "### Pulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead9fcda-ddf3-4a82-9140-92cf2fb555c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pulls_filename = \"model_pulls_\" + \"voting_\" + f\"{todaysdate}.sav\"\n",
    "\n",
    "# Define the individual models in the ensemble\n",
    "models = [\n",
    "    LogisticRegression(solver='lbfgs', max_iter=20),  \n",
    "    LogisticRegression(solver='saga', max_iter=20),   \n",
    "    # MLPClassifier(hidden_layer_sizes=(100,100), activation='relu', random_state=1, max_iter=100),  \n",
    "    ]\n",
    "\n",
    "\n",
    "# Create the ensemble classifier using VotingClassifier\n",
    "model_pulls = VotingClassifier(estimators=[('model'+str(i+1), model) for i, model in enumerate(models)], voting='soft', n_jobs=-2).fit(X_train[pull_inputs3], X_train[['pulled']].values.ravel())\n",
    "\n",
    "# Save model\n",
    "pickle.dump(model_pulls, open(os.path.join(model_path, pulls_filename), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbdf233-faa3-465d-b6e7-0c5fe7db1ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "proba = model_pulls.predict_proba(X_test[pull_inputs3])\n",
    "X_test['is_kept_pred'] = proba[:, 0]  # Assign the first column of probabilities\n",
    "X_test['is_pulled_pred'] = proba[:, 1]  # Assign the second column of probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d852fc0-0084-4a8d-aad5-ffc5319aa717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add xtiles (to examine how well predictions match actual results)\n",
    "X_test['decile'] = pd.qcut(X_test['is_pulled_pred'], 10, labels=False)\n",
    "\n",
    "df_name = \"is_pulled\" + \"_df\"\n",
    "globals()[df_name] = X_test.groupby('decile').mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa3d122-b7c9-4964-9ca6-68e4374f19ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figures\n",
    "plt.plot(is_pulled_df['decile'], is_pulled_df['is_pulled_pred'], color='red')\n",
    "plt.plot(is_pulled_df['decile'], is_pulled_df['pulled'], color='black')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec0abaa-bd59-4151-88db-0e6aaf90549c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
