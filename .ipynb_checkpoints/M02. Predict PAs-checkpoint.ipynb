{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "246dcb35-a0f2-4ce2-a46e-f6b8c1053bf2",
   "metadata": {},
   "source": [
    "# M02. Predict PAs\n",
    "- Predict outs vs. safe\n",
    "- Predict out type\n",
    "- Predict safe type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4534de56-4550-4dce-99fc-73d526095998",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"U1. Imports.ipynb\"\n",
    "%run \"U2. Utilities.ipynb\"\n",
    "%run \"U3. Classes.ipynb\"\n",
    "# %run \"D3. Simulation Functions.ipynb\"\n",
    "\n",
    "baseball_path = r'C:\\Users\\james\\Documents\\MLB\\Database'\n",
    "\n",
    "db_path = r'C:\\Users\\james\\Documents\\MLB\\Database\\MLBDB.db'\n",
    "engine = create_engine(f'sqlite:///{db_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d007683e-abe8-4fa1-bc35-8ecdd3ee63b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import log_loss, classification_report, f1_score, make_scorer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from tensorflow import keras\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ff8569-0a21-4440-888e-7bf33c4821da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b329e039-ddf8-46ac-ade2-bcd519279b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"A03. Steamer.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a6014a-eb27-4083-9537-1ec7e127de15",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfe2881-7c98-44ec-99de-aae0a9a9df31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the last instance of each player in each game, assuming they have enough PAs\n",
    "sql_query = f'''\n",
    "    SELECT *\n",
    "    FROM \"Dataset\"\n",
    "'''\n",
    "\n",
    "complete_dataset = pd.read_sql_query(sql_query, con=engine)\n",
    "\n",
    "# Remove those with missing data\n",
    "complete_dataset.dropna(subset=batter_stats, inplace=True)\n",
    "complete_dataset.dropna(subset=pitcher_stats, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c597e0d-ca5c-4569-9fde-ab1c97184f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_usage = complete_dataset.memory_usage(deep=True).sum()\n",
    "print(f\"Memory usage of the DataFrame: {memory_usage / (1024 ** 2):.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee27de4-ce5b-47c5-a4cf-c830466c46c8",
   "metadata": {},
   "source": [
    "##### Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e567e5-b2ec-4a6a-b817-581527adc6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batters\n",
    "with open(os.path.join(model_path, \"batter_stats_scaler_20231027.pkl\"), \"rb\") as file:\n",
    "    batter_stats_scaler = pickle.load(file)\n",
    "# Pitchers\n",
    "with open(os.path.join(model_path, \"pitcher_stats_scaler_20231027.pkl\"), \"rb\") as file:\n",
    "    pitcher_stats_scaler = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52508861-52f1-4d58-8c14-f481006a1674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize\n",
    "complete_dataset[batter_stats] = batter_stats_scaler.fit_transform(complete_dataset[batter_stats])\n",
    "complete_dataset[pitcher_stats] = pitcher_stats_scaler.fit_transform(complete_dataset[pitcher_stats])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31af98da-c1d1-43f0-a38d-7992b6b96f0a",
   "metadata": {},
   "source": [
    "### Steamer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bd4f4e-9abe-498d-a2bc-a9d8cd94e074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the last instance of each player in each game, assuming they have enough PAs\n",
    "sql_query = f'''\n",
    "  SELECT *\n",
    "  FROM \"Steamer Hitters\"\n",
    "'''\n",
    "\n",
    "steamer_hitters_df = pd.read_sql_query(sql_query, con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4194d026-dbb6-43c7-aed1-0ba7f2dcc416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean\n",
    "steamer_hitters_df2 = clean_steamer_hitters(steamer_hitters_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd7e3e9-972d-4767-a793-57c48e6aac6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the last instance of each player in each game, assuming they have enough PAs\n",
    "sql_query = f'''\n",
    "  SELECT *\n",
    "  FROM \"Steamer Pitchers\"\n",
    "'''\n",
    "\n",
    "steamer_pitchers_df = pd.read_sql_query(sql_query, con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc05c0e-a762-4dd1-b624-0a3eef35f58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean\n",
    "steamer_pitchers_df2 = clean_steamer_pitchers(steamer_pitchers_df)\n",
    "steamer_pitchers_df2.dropna(subset=pitcher_stats_fg2, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d043182-c871-4c59-ba1b-5624a35e5580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batters\n",
    "with open(os.path.join(model_path, \"batter_stats_fg_scaler_20231027.pkl\"), \"rb\") as file:\n",
    "    batter_stats_fg_scaler = pickle.load(file)\n",
    "# Pitchers\n",
    "with open(os.path.join(model_path, \"pitcher_stats_fg_scaler_20231027.pkl\"), \"rb\") as file:\n",
    "    pitcher_stats_fg_scaler = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96034fe3-b3ea-4798-a317-14644903ba52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize\n",
    "steamer_hitters_df2[batter_stats_fg] = batter_stats_fg_scaler.fit_transform(steamer_hitters_df2[batter_stats_fg])\n",
    "steamer_pitchers_df2[pitcher_stats_fg2] = pitcher_stats_fg_scaler.fit_transform(steamer_pitchers_df2[pitcher_stats_fg2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c115569b-2eb1-4689-976b-2bec2de41de2",
   "metadata": {},
   "source": [
    "### Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74aac58-6b72-4d70-992a-234693ddd528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the dates of Steamer projections\n",
    "# We'll take the most recent and merge in that projection for each player\n",
    "batter_steamer_dates = list(steamer_hitters_df2['date'].unique())\n",
    "pitcher_steamer_dates = list(steamer_pitchers_df2['date'].unique())\n",
    "\n",
    "# Define a function to find the largest number in \"steamer_dates\" less than or equal to a given \"date\"\n",
    "def find_steamer_date(date, steamer_dates):\n",
    "    max_steamer_date = max(filter(lambda d: d <= date, steamer_dates), default=None)\n",
    "    return max_steamer_date\n",
    "\n",
    "# Apply the function to create the \"steamer_date\" column in your DataFrame\n",
    "complete_dataset[\"batter_date\"] = complete_dataset[\"date\"].apply(lambda x: find_steamer_date(x, batter_steamer_dates))\n",
    "complete_dataset[\"pitcher_date\"] = complete_dataset[\"date\"].apply(lambda x: find_steamer_date(x, pitcher_steamer_dates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4e33a6-b7e1-4740-94c5-0dc6515b6227",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de79d10-e324-4580-be44-eb38ba412b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Steamer stats we want to keep\n",
    "batter_stats_fg_plus = ['mlbamid', 'steamerid', 'date'] + batter_stats_fg \n",
    "pitcher_stats_fg_plus = ['mlbamid', 'steamerid', 'date'] + pitcher_stats_fg \n",
    "# Merge\n",
    "complete_merged_df = pd.merge(complete_dataset, steamer_hitters_df2[batter_stats_fg_plus], left_on=['batter', 'batter_date'], right_on=['mlbamid', 'date'], how='inner')\n",
    "complete_merged_df = pd.merge(complete_merged_df, steamer_pitchers_df2[pitcher_stats_fg_plus], left_on=['pitcher', 'pitcher_date'], right_on=['mlbamid', 'date'], how='inner')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455ace11-7229-4b30-bf8f-d39d3d778dc5",
   "metadata": {},
   "source": [
    "### Impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9499a5-8581-42e1-9971-70ee84b6f461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batters\n",
    "with open(os.path.join(model_path, \"batter_imputations_model_20231027.pkl\"), \"rb\") as file:\n",
    "    batter_imputations_model = pickle.load(file)\n",
    "# Pitchers\n",
    "with open(os.path.join(model_path, \"pitcher_imputations_model_20231027.pkl\"), \"rb\") as file:\n",
    "    pitcher_imputations_model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500f4ca2-ffde-4601-90d1-44826dc538f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add hands to use in imputation\n",
    "batter_stats_fg_imp = batter_stats_fg + ['b_L', 'p_L']\n",
    "pitcher_stats_fg_imp = pitcher_stats_fg + ['b_L', 'p_L']\n",
    "\n",
    "### Batters\n",
    "# Use Steamer stats to predict API/Statcast stats for those with limited samples\n",
    "batter_predictions = batter_imputations_model.predict(complete_merged_df.loc[complete_merged_df['pa_b'] < 40, batter_stats_fg_imp])\n",
    "\n",
    "# Impute inputs with limited sample size with predicted values\n",
    "complete_merged_df.loc[complete_merged_df['pa_b'] < 40, batter_stats] = batter_predictions\n",
    "\n",
    "### Pitchers\n",
    "# Use Steamer stats to predict API/Statcast stats for those with limited samples\n",
    "pitcher_predictions = pitcher_imputations_model.predict(complete_merged_df.loc[complete_merged_df['pa_p'] < 40, pitcher_stats_fg_imp])\n",
    "\n",
    "# Impute inputs with limited sample size with predicted values\n",
    "complete_merged_df.loc[complete_merged_df['pa_p'] < 40, pitcher_stats] = pitcher_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd014dbb-e276-4844-8f47-de639c24c3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create imputation flags (could move this up, might make more sense)\n",
    "complete_merged_df['imp_b'] = (complete_merged_df['pa_b'] < 40).astype('int')\n",
    "complete_merged_df['imp_p'] = (complete_merged_df['pa_p'] < 40).astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ddb37c-4952-4f64-8adf-2041ee2d1fb4",
   "metadata": {},
   "source": [
    "### Train Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477bd072-5b6a-4fd0-a1e8-a6684523b347",
   "metadata": {},
   "source": [
    "##### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304246a9-c7ee-4c4d-8783-95b85f601287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out events that didn't end with reaching base or an out\n",
    "complete_merged_df = complete_merged_df.query('eventsModel != \"Cut\"').reset_index(drop=True)\n",
    "# Drop early observations (these will generally treat veterans as rookies and could bias results\n",
    "complete_merged_df = complete_merged_df.drop(index=complete_merged_df.index[:20000])\n",
    "complete_merged_df.reset_index(inplace=True, drop=True)\n",
    "# Create year variable\n",
    "complete_merged_df['year'] = complete_merged_df['date'].astype('str').str[:4]\n",
    "# Create is_out binary variable\n",
    "out_list = ['so', 'fo', 'go', 'lo', 'po']\n",
    "complete_merged_df['is_out'] = complete_merged_df['eventsModel'].str.contains('|'.join(out_list)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742b9d1f-25fe-4ae2-8144-d73a99d3d582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep relevant variables\n",
    "keep_list = pa_inputs2 + ['pa_b', 'pa_p', 'year', 'is_out', 'eventsModel']\n",
    "model_dataset = complete_merged_df[keep_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf781d0f-ba06-4dc8-a82b-157ad1fea64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "outs_dataset = model_dataset[model_dataset['eventsModel'].isin(['so', 'lo', 'go', 'fo', 'po'])].copy()\n",
    "safe_dataset = model_dataset[~model_dataset['eventsModel'].isin(['so', 'lo', 'go', 'fo', 'po'])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b1ffac-682b-47fd-b3cb-62f0965b47da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and testing groups\n",
    "X_train = model_dataset.groupby(model_dataset['year']).apply(lambda x: x.head(int(len(x)*2/3)))\n",
    "X_test = model_dataset.groupby(model_dataset['year']).apply(lambda x: x.tail(int(len(x)*1/3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f894519-3614-4045-839f-aeb4c55ec76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "outs_dataset_train = X_train[X_train['eventsModel'].isin(['so', 'lo', 'go', 'fo', 'po'])].copy()\n",
    "safe_dataset_train = X_train[~X_train['eventsModel'].isin(['so', 'lo', 'go', 'fo', 'po'])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67fbbcc-924e-4b06-a197-815283a6b00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "outs_dataset_test = X_test[X_test['eventsModel'].isin(['so', 'lo', 'go', 'fo', 'po'])].copy()\n",
    "safe_dataset_test = X_test[~X_test['eventsModel'].isin(['so', 'lo', 'go', 'fo', 'po'])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb30e14-a7d8-4368-a39b-bca912c1d93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "del complete_dataset, complete_merged_df, model_dataset, steamer_hitters_df, steamer_hitters_df2, steamer_pitchers_df, steamer_pitchers_df2  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a191091-9148-4aa5-8d4f-0ab347592f7b",
   "metadata": {},
   "source": [
    "### Outs vs. Safe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead9fcda-ddf3-4a82-9140-92cf2fb555c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "binary_filename = \"model_binary_\" + \"voting_\" + f\"{todaysdate}.sav\"\n",
    "\n",
    "# Define the individual models in the ensemble\n",
    "models = [\n",
    "    LogisticRegression(solver='lbfgs', max_iter=20),  \n",
    "    LogisticRegression(solver='saga', max_iter=20),   \n",
    "    # MLPClassifier(hidden_layer_sizes=(100,100), activation='relu', random_state=1, max_iter=100),  \n",
    "    ]\n",
    "\n",
    "\n",
    "# Create the ensemble classifier using VotingClassifier\n",
    "model_binary = VotingClassifier(estimators=[('model'+str(i+1), model) for i, model in enumerate(models)], voting='soft', n_jobs=-2).fit(X_train[pa_inputs2], X_train[['is_out']].values.ravel())\n",
    "\n",
    "# Save model\n",
    "pickle.dump(model_binary, open(os.path.join(model_path, binary_filename), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbdf233-faa3-465d-b6e7-0c5fe7db1ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "proba = model_binary.predict_proba(X_test[pa_inputs2])\n",
    "X_test['is_safe_pred'] = proba[:, 0]  # Assign the first column of probabilities\n",
    "X_test['is_out_pred'] = proba[:, 1]  # Assign the second column of probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d852fc0-0084-4a8d-aad5-ffc5319aa717",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add xtiles (to examine how well predictions match actual results)\n",
    "# model_dataset['decile'] = pd.qcut(model_dataset['is_out_pred'], 10, labels=False)\n",
    "\n",
    "# df_name = \"is_out\" + \"_df\"\n",
    "# globals()[df_name] = model_dataset.groupby('decile').mean().reset_index()\n",
    "\n",
    "X_test['decile'] = pd.qcut(X_test['is_out_pred'], 10, labels=False)\n",
    "\n",
    "df_name = \"is_out\" + \"_df\"\n",
    "globals()[df_name] = X_test.query('imp_b == 1').query('imp_p == 1').groupby('decile').mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa3d122-b7c9-4964-9ca6-68e4374f19ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figures\n",
    "plt.plot(is_out_df['decile'], is_out_df['is_out_pred'], color='red')\n",
    "plt.plot(is_out_df['decile'], is_out_df['is_out'], color='black')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abea0ff-2655-4096-8b95-b40f147e2805",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3aa9d924-5ce5-41bc-8df3-fc2602fbad21",
   "metadata": {},
   "source": [
    "### Outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2bd13a-a027-41d9-9203-9e8caf1da45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Neural network layers\n",
    "layers = (30,30,30)\n",
    "# To string\n",
    "layers_str = ''.join(str(x) for x in layers)\n",
    "# Activation method\n",
    "activation = 'relu'\n",
    "# Iterations\n",
    "iters = 15\n",
    "\n",
    "outs_filename = f\"model_outs_{activation}_{layers_str}_{iters}_{todaysdate}.sav\"\n",
    "print(outs_filename)\n",
    "\n",
    "# Define the individual models in the ensemble\n",
    "models = [\n",
    "    MLPClassifier(hidden_layer_sizes=(layers), activation=activation, verbose=True, alpha=0.0001, early_stopping=True, validation_fraction=0.1, random_state=1, max_iter=iters),\n",
    "    MLPClassifier(hidden_layer_sizes=(layers), activation=activation, verbose=True, alpha=0.0001, early_stopping=True, validation_fraction=0.1, random_state=2, max_iter=iters),\n",
    "    MLPClassifier(hidden_layer_sizes=(layers), activation=activation, verbose=True, alpha=0.0001, early_stopping=True, validation_fraction=0.1, random_state=3, max_iter=iters),\n",
    "]\n",
    "\n",
    "# Create the ensemble classifier using VotingClassifier\n",
    "model_outs = VotingClassifier(estimators=[('model'+str(i+1), model) for i, model in enumerate(models)], voting='soft', n_jobs=-2).fit(outs_dataset_train[pa_inputs2], outs_dataset_train[['eventsModel']].values.ravel())\n",
    "\n",
    "# Save model\n",
    "pickle.dump(model_outs, open(os.path.join(model_path, outs_filename), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97405dd2-7c8e-4fdd-af0d-95da09f878b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict out types\n",
    "outs_outputs = list(model_outs.classes_)\n",
    "outs_outputs_pred = [x + \"_pred\" for x in outs_outputs]\n",
    "\n",
    "proba = model_outs.predict_proba(outs_dataset_test[pa_inputs2])\n",
    "for i, col in enumerate(outs_outputs_pred):\n",
    "    outs_dataset_test[f'{col}'] = proba[:, i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b540717e-82bd-478a-bd39-6d1e1e7d0bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create deciles\n",
    "for var in outs_outputs:\n",
    "    outs_dataset_test[f'{var}_act'] = (outs_dataset_test['eventsModel'] == var).astype('int')\n",
    "    outs_dataset_test['decile'] = pd.qcut(outs_dataset_test[f'{var}_pred'], 10, labels=False)\n",
    "    df_name = var + \"_df\"\n",
    "    globals()[df_name] = outs_dataset_test.query('imp_b == 1').query('imp_p == 1').groupby('decile').mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea5a925-fe18-418c-b64b-cc635d59cf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figures\n",
    "fig, axs = plt.subplots(2, 3, figsize=(12, 8))\n",
    "\n",
    "for i, var in enumerate(outs_outputs):\n",
    "    row = i // 3  # Calculate the row index based on the iteration\n",
    "    col = i % 3   # Calculate the column index based on the iteration\n",
    "    df_name = var + \"_df\"\n",
    "    axs[row, col].plot(globals()[df_name]['decile'], globals()[df_name][f'{var}_pred'], color='red')\n",
    "    axs[row, col].plot(globals()[df_name]['decile'], globals()[df_name][f'{var}_act'], color='black')\n",
    "    axs[row, col].set_title(var)\n",
    "    # axs[row, col].set_ylim(0,0.35)\n",
    "\n",
    "\n",
    "# Add some space between subplots to prevent overlapping\n",
    "fig.tight_layout(pad=.0)\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70643840-d641-4549-9a23-3f14a2c2613e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8fe77ff2-1518-4c0e-907a-a3706f86cae5",
   "metadata": {},
   "source": [
    "### Safe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced6b458-2a2d-4a61-9780-c9c4943df704",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Neural network layers\n",
    "layers = (30,30,30,30,30)\n",
    "# To string\n",
    "layers_str = ''.join(str(x) for x in layers)\n",
    "# Activation method\n",
    "activation = 'relu'\n",
    "# Iterations\n",
    "iters = 30\n",
    "\n",
    "safe_filename = f\"model_safe_{activation}_{layers_str}_{iters}_{todaysdate}.sav\"\n",
    "print(safe_filename)\n",
    "\n",
    "# Define the individual models in the ensemble\n",
    "models = [\n",
    "    MLPClassifier(hidden_layer_sizes=(layers), activation=activation, verbose=True, alpha=0.0001, early_stopping=True, validation_fraction=0.1, random_state=1, max_iter=iters),\n",
    "    MLPClassifier(hidden_layer_sizes=(layers), activation=activation, verbose=True, alpha=0.0001, early_stopping=True, validation_fraction=0.1, random_state=2, max_iter=iters),\n",
    "    MLPClassifier(hidden_layer_sizes=(layers), activation=activation, verbose=True, alpha=0.0001, early_stopping=True, validation_fraction=0.1, random_state=3, max_iter=iters),\n",
    "]\n",
    "\n",
    "# Create the ensemble classifier using VotingClassifier\n",
    "model_safe = VotingClassifier(estimators=[('model'+str(i+1), model) for i, model in enumerate(models)], voting='soft', n_jobs=-2).fit(safe_dataset_train[pa_inputs2], safe_dataset_train[['eventsModel']].values.ravel())\n",
    "\n",
    "# Save model\n",
    "pickle.dump(model_safe, open(os.path.join(model_path, safe_filename), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c72f07-9f7d-4143-a664-f1219bb131b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict safe types\n",
    "safe_outputs = list(model_safe.classes_)\n",
    "safe_outputs_pred = [x + \"_pred\" for x in safe_outputs]\n",
    "\n",
    "proba = model_safe.predict_proba(safe_dataset_test[pa_inputs2])\n",
    "for i, col in enumerate(safe_outputs_pred):\n",
    "    safe_dataset_test[f'{col}'] = proba[:, i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb77236-8a0a-49eb-b701-007078d47ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create deciles\n",
    "for var in safe_outputs:\n",
    "    safe_dataset_test[f'{var}_act'] = (safe_dataset_test['eventsModel'] == var).astype('int')\n",
    "    safe_dataset_test['decile'] = pd.qcut(safe_dataset_test[f'{var}_pred'], 10, labels=False)\n",
    "    df_name = var + \"_df\"\n",
    "    globals()[df_name] = safe_dataset_test.query('imp_b == 0').query('imp_p == 0').groupby('decile').mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26b3875-8760-4396-96ef-b6897886fabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figures\n",
    "fig, axs = plt.subplots(2, 3, figsize=(12, 8))\n",
    "\n",
    "for i, var in enumerate(safe_outputs):\n",
    "    row = i // 3  # Calculate the row index based on the iteration\n",
    "    col = i % 3   # Calculate the column index based on the iteration\n",
    "    df_name = var + \"_df\"\n",
    "    axs[row, col].plot(globals()[df_name]['decile'], globals()[df_name][f'{var}_pred'], color='red')\n",
    "    axs[row, col].plot(globals()[df_name]['decile'], globals()[df_name][f'{var}_act'], color='black')\n",
    "    axs[row, col].set_title(var)\n",
    "    # axs[row, col].set_ylim(globals()[df_name][f'{var}_act'].min(),globals()[df_name][f'{var}_act'].max())\n",
    "\n",
    "\n",
    "# Add some space between subplots to prevent overlapping\n",
    "fig.tight_layout(pad=.0)\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dea64b-3796-42cf-8c90-463bc7398314",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96987f01-3231-4e1f-8bc5-a2d7c46ee86f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
