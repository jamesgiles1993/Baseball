{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97889d6e-5f18-43ff-8d81-a6cbbe691269",
   "metadata": {},
   "source": [
    "# A02. MLB API\n",
    "Sources: \n",
    "- MLB Stats API\n",
    "- Statcast (via pybaseball package)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88a1b14-ddf6-4824-bdb0-7f50d2de4112",
   "metadata": {},
   "source": [
    "### 1. MLB Stats API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7eaaab5-d577-4cb0-a23d-d81bdbd82501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in boxscore for weather\n",
    "def create_box(gamePk):\n",
    "    # Read in boxscore as json\n",
    "    box = pd.json_normalize(statsapi.boxscore_data(gamePk, timecode=None), record_path='gameBoxInfo')\n",
    "    \n",
    "    # Define default values\n",
    "    default_weather = \"75 degrees, Clear.\"\n",
    "    default_wind = \"0 mph, L To R.\"\n",
    "    default_venue = \"Missing Park.\"\n",
    "    default_date = \"November 30, 1993\"\n",
    "    \n",
    "    # Extract weather, wind, venue, and date\n",
    "    weather = box.loc[box['label'] == \"Weather\", \"value\"].item() if 'Weather' in box['label'].values else default_weather\n",
    "    wind = box.loc[box['label'] == \"Wind\", \"value\"].item() if 'Wind' in box['label'].values else default_wind\n",
    "    venue = box.loc[box['label'] == \"Venue\", \"value\"].item() if 'Venue' in box['label'].values else default_venue\n",
    "    \n",
    "    try:\n",
    "        date = box.iloc[-1, box.columns.get_loc('label')]\n",
    "    except:\n",
    "        date = default_date\n",
    "    \n",
    "    return weather, wind, venue, date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bbf769d-2eb2-4393-ac68-5fb6e2dfc8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract field or provide default (helper function)\n",
    "def extract_field(data, field, default=None):\n",
    "    try:\n",
    "        return data[field]\n",
    "    except:\n",
    "        return default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55a26df1-70a9-43e6-b901-c009aa7cacd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exract play by play data\n",
    "def create_game(gamePk):\n",
    "    game = statsapi.get('game_playByPlay', {'gamePk': gamePk})\n",
    "    \n",
    "    # Create list with relevant variables\n",
    "    game_data = []\n",
    "    for play in game['allPlays']:\n",
    "        about = play['about']\n",
    "        count = play['count']\n",
    "        result = play['result']\n",
    "        matchup = play['matchup']\n",
    "        runners = play['runners']\n",
    "        \n",
    "        atBatIndex = about['atBatIndex']\n",
    "        inning = about['inning']\n",
    "        halfInning = about['halfInning']\n",
    "        outs = count['outs']\n",
    "        \n",
    "        type = extract_field(result, 'type')\n",
    "        event = extract_field(result, 'event')\n",
    "        eventType = extract_field(result, 'eventType')\n",
    "        description = extract_field(result, 'description')\n",
    "        rbi = extract_field(result, 'rbi', 0)\n",
    "        awayScore = extract_field(result, 'awayScore', 0)\n",
    "        homeScore = extract_field(result, 'homeScore', 0)\n",
    "        \n",
    "        batter = extract_field(matchup['batter'], 'id', 999999)\n",
    "        batterName = extract_field(matchup['batter'], 'fullName', 'Missing Name')\n",
    "        batSide = extract_field(matchup['batSide'], 'code', 'R')\n",
    "        pitcher = extract_field(matchup['pitcher'], 'id', 999999)\n",
    "        pitcherName = extract_field(matchup['pitcher'], 'fullName', 'Missing Name')\n",
    "        pitchHand = extract_field(matchup['pitchHand'], 'code', 'R')\n",
    "        \n",
    "        # Baserunner on base at the end of the play\n",
    "        postOnFirst = extract_field(matchup, 'postOnFirst', None)\n",
    "        postOnSecond = extract_field(matchup, 'postOnSecond', None)\n",
    "        postOnThird = extract_field(matchup, 'postOnThird', None)\n",
    "        \n",
    "        # Extract base runner information\n",
    "        for runner in runners:\n",
    "            details = runner['details']\n",
    "            movement = runner['movement']\n",
    "            \n",
    "            runner_id = details['runner']['id']\n",
    "            start = movement['start']\n",
    "            end = movement['end']\n",
    "            movementReason = details['movementReason']\n",
    "            \n",
    "            game_data.append([atBatIndex, inning, halfInning, outs, type, runner_id, event, eventType, description, \n",
    "                              rbi, awayScore, homeScore, batter, batterName, batSide, pitcher, pitcherName, pitchHand, \n",
    "                              postOnFirst, postOnSecond, postOnThird, start, end, movementReason])\n",
    "    \n",
    "    # Create dataframe\n",
    "    df = pd.DataFrame(game_data, columns=['atBatIndex', 'inning', 'halfInning', 'outs', 'type', 'id', 'event', 'eventType', 'description', \n",
    "                                          'rbi', 'awayScore', 'homeScore', 'batter', 'batterName', 'batSide', 'pitcher', \n",
    "                                          'pitcherName', 'pitchHand', 'postOnFirst', 'postOnSecond', 'postOnThird', 'start', 'end', 'movementReason'])\n",
    " \n",
    "    # Assuming 'create_box' function exists\n",
    "    weather, wind, venue, date = create_box(gamePk)\n",
    "    df['gamePk'] = gamePk\n",
    "    df['weather'] = weather\n",
    "    df['wind'] = wind\n",
    "    df['venue'] = venue\n",
    "    df['date'] = date\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "560bfa6a-933b-4f2a-991e-5824f736c699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract API data\n",
    "def plays_statsapi(start_date, end_date):\n",
    "    # Extract year\n",
    "    year = start_date[-4:]\n",
    "    \n",
    "    # Read in schedule\n",
    "    games = statsapi.schedule(start_date=start_date, end_date=end_date)\n",
    "\n",
    "    # Use a list comprehension to extract unique game_ids\n",
    "    game_ids = list(game['game_id'] for game in games)\n",
    "    away_names = list(game['away_name'] for game in games)\n",
    "    home_names = list(game['home_name'] for game in games)\n",
    "    game_dates = list(game['game_date'] for game in games)\n",
    "    game_types = list(game['game_type'] for game in games)\n",
    "    venue_ids = list(game['venue_id'] for game in games)\n",
    "\n",
    "    # Run all in parallel\n",
    "    df_list = Parallel(n_jobs=-1, verbose=0)(delayed(create_game)(gamePk=game_id) for game_id in game_ids)\n",
    "\n",
    "    # Add additional information from schedule\n",
    "    for i in range(len(df_list)):\n",
    "        df_list[i]['away_name'] = away_names[i]\n",
    "        df_list[i]['home_name'] = home_names[i]\n",
    "        df_list[i]['game_date'] = game_dates[i]\n",
    "        df_list[i]['game_type'] = game_types[i]\n",
    "        df_list[i]['venue_id'] = venue_ids[i]\n",
    "    \n",
    "    # Append all dataframes together\n",
    "    df = pd.concat(df_list, axis=0)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0a8bd2-7f27-4892-a075-51aab2946062",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b5008ae7-cd0e-4017-a433-d5ee20fc1d2b",
   "metadata": {},
   "source": [
    "### 2. Statcast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22b1278d-8592-4f62-adb0-157c2c91e6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Statcast data\n",
    "def plays_statcast(start_date, end_date):\n",
    "    # Extract year\n",
    "    year = start_date[:4]\n",
    "    \n",
    "    # Use pybaseball to read in Statcast data\n",
    "    data = statcast(start_date, end_date)\n",
    "    \n",
    "    # Create atBatIndex compatible with Statsapi\n",
    "    data['atBatIndex'] = data['at_bat_number'] - 1 \n",
    "    \n",
    "    # Highest level during the at bat\n",
    "    data['maxSpeed'] = data.groupby(['game_pk', 'atBatIndex'])['effective_speed'].transform(max)\n",
    "    data['maxSpin'] = data.groupby(['game_pk', 'atBatIndex'])['release_spin_rate'].transform(max)\n",
    "    \n",
    "    # Convert to numeric for sorting\n",
    "    data['game_pk'] = data['game_pk'].astype('int')\n",
    "    data['atBatIndex'] = data['atBatIndex'].astype('int')\n",
    "    data['pitch_number'] = data['pitch_number'].astype('int')\n",
    "    \n",
    "    # Only want the deciding (last) pitch\n",
    "    data.sort_values(['game_pk', 'atBatIndex', 'pitch_number'], inplace=True)\n",
    "    data.drop_duplicates(['game_pk', 'atBatIndex'], keep='last', inplace=True)\n",
    "    \n",
    "    data.rename(columns={'game_pk':'gamePk'}, inplace=True)\n",
    "    \n",
    "    # Keep relevant variables\n",
    "    keep_list = ['gamePk', 'atBatIndex', 'pitch_number', 'pitch_name', 'game_type',\n",
    "                 'hc_x', 'hc_y', 'hit_location', 'hit_distance_sc', 'launch_speed', 'launch_angle', 'launch_speed_angle',\n",
    "                 'woba_value', 'woba_denom', 'estimated_ba_using_speedangle', 'estimated_woba_using_speedangle',\n",
    "                 'iso_value', 'babip_value',\n",
    "                 'maxSpeed', 'maxSpin']\n",
    "                \n",
    "    data = data[keep_list]\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2817da46-f39c-4188-9b3b-04c919370a6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63434032-97a4-4a86-b204-52d962905c77",
   "metadata": {},
   "source": [
    "### 3. Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a57409e8-46f3-41a3-8989-be85ad306eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge together datasets in year range\n",
    "def dataset(engine, start_year, end_year):\n",
    "    # Initialize an empty dataframe to store the results\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    # Iterate through the range of years\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        # Define table names for Stats API and Statcast for the current year\n",
    "        statsapi_table = f'Stats API {year}'\n",
    "        statcast_table = f'Statcast {year}'\n",
    "        \n",
    "        # Load tables from the database for the current year\n",
    "        statsapi_df = pd.read_sql_table(statsapi_table, engine)\n",
    "        statcast_df = pd.read_sql_table(statcast_table, engine)\n",
    "        \n",
    "        # Merge the two dataframes based on 'gamePk' and 'atBatIndex'\n",
    "        merged_df = pd.merge(statsapi_df, statcast_df, on=['gamePk', 'atBatIndex'], how='left')\n",
    "        \n",
    "        # Append the merged dataframe to the result dataframe\n",
    "        df = df.append(merged_df, ignore_index=True)\n",
    "        \n",
    "        # Create data variable (without dashes)\n",
    "        df['date'] = df['game_date'].str.replace('-', '')\n",
    "        \n",
    "        # Convert to numeric for sorting\n",
    "        df['date'] = df['date'].astype('int')\n",
    "        df['gamePk'] = df['gamePk'].astype('int')\n",
    "        df['atBatIndex'] = df['atBatIndex'].astype('int')\n",
    "        \n",
    "        # Sort\n",
    "        df.sort_values(['game_date', 'gamePk', 'atBatIndex'], ascending=True, inplace=True)\n",
    "\n",
    "        # Only keep one observation per at bat\n",
    "        df.drop_duplicates(['gamePk', 'atBatIndex'], keep='last', inplace=True)\n",
    "    \n",
    "    # Return the combined dataframe\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315d5b07-b494-4bfc-a154-90d60018de12",
   "metadata": {},
   "source": [
    "##### Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe770413-e196-4f24-81e4-af1d677f765f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positive to centerfield, negative from centerfield\n",
    "def y_vect(df):\n",
    "    wind_speed = df['windSpeed']\n",
    "    angled = df['windSpeed'] / 2 * math.sqrt(2)\n",
    "    \n",
    "    if df['windDirection'] == \"Out To CF\": \n",
    "        y_vect = wind_speed\n",
    "    elif df['windDirection'] == \"Out To RF\": \n",
    "        y_vect = angled\n",
    "    elif df['windDirection'] == \"L To R\": \n",
    "        y_vect = 0\n",
    "    elif df['windDirection'] == \"In From LF\": \n",
    "        y_vect = angled * -1\n",
    "    elif df['windDirection'] == \"In From CF\": \n",
    "        y_vect = wind_speed * - 1\n",
    "    elif df['windDirection'] == \"In From RF\": \n",
    "        y_vect = angled * -1\n",
    "    elif df['windDirection'] == \"R To L\": \n",
    "        y_vect = 0\n",
    "    elif df['windDirection'] == \"Out To LF\": \n",
    "        y_vect = angled\n",
    "    else:\n",
    "        y_vect = 0\n",
    "        \n",
    "    return y_vect\n",
    "\n",
    "# Positive from left to right, negative from right to left\n",
    "def x_vect(df):\n",
    "    wind_speed = df['windSpeed']\n",
    "    angled = df['windSpeed'] / 2 * math.sqrt(2)\n",
    "    \n",
    "    if df['windDirection'] == \"L To R\": \n",
    "        x_vect = wind_speed\n",
    "    elif df['windDirection'] == \"In From LF\": \n",
    "        x_vect = angled\n",
    "    elif df['windDirection'] == \"In From CF\": \n",
    "        x_vect = 0\n",
    "    elif df['windDirection'] == \"In From RF\": \n",
    "        x_vect = angled * -1\n",
    "    elif df['windDirection'] == \"R To L\": \n",
    "        x_vect = wind_speed * - 1\n",
    "    elif df['windDirection'] == \"Out To LF\": \n",
    "        x_vect = angled * -1\n",
    "    elif df['windDirection'] == \"Out To CF\": \n",
    "        x_vect = 0\n",
    "    elif df['windDirection'] == \"Out To RF\": \n",
    "        x_vect = angled\n",
    "    else:\n",
    "        x_vect = 0\n",
    "        \n",
    "    return x_vect\n",
    "\n",
    "# 2 is to centerfield, 6 is from centerfield, clockwise\n",
    "# Assumption is wind is blowing in 8 cardinal directions, so we can use simple right isosceles triangles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fd07eb1-f8ea-490a-9116-288b54e6f5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_weather(df):   \n",
    "    # Separate weather into temperature and weather type\n",
    "    df[['temperature', 'weather']] = df['weather'].str.split(\", \", expand=True)\n",
    "    df['temperature'] = df['temperature'].str.replace(\" degrees\", \"\").astype('int')\n",
    "    # Separate wind into speed and direction\n",
    "    df[['windSpeed', 'windDirection']] = df['wind'].str.split(\", \", expand=True)\n",
    "    df['windSpeed'].fillna(\"0 mph\", inplace=True)\n",
    "    df['windSpeed'] = df['windSpeed'].str.replace(\" mph\", \"\")\n",
    "    df['windSpeed'] = pd.to_numeric(df['windSpeed'], errors='coerce')\n",
    "    df['windSpeed'].fillna(0, inplace=True)\n",
    "    df['windDirection'].fillna('L to R', inplace=True)\n",
    "    df['windSpeed'].unique()\n",
    "    df['windDirection'] = df['windDirection'].str.replace(\".\", \"\")\n",
    "    # Calculate vectors\n",
    "    df['x_vect'] = df.apply(x_vect, axis=1)\n",
    "    df['y_vect'] = df.apply(y_vect, axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00b1894-a0fe-4b7f-acf6-6a61b1cf0378",
   "metadata": {},
   "source": [
    "##### Model Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0c0bed1-43d5-4976-8bbc-3d3743518e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign play categories to full descriptions\n",
    "def create_events(df):\n",
    "    event_mapping = {\n",
    "        'Strikeout': 'so',\n",
    "        'Strikeout Double Play': 'so',\n",
    "        'Groundout': 'go',\n",
    "        'Fielders Choice': 'go',\n",
    "        'Double Play': 'go',\n",
    "        'Grounded Into DP': 'go',\n",
    "        'Triple Play': 'go',\n",
    "        'Field Error': 'go',\n",
    "        'Forceout': 'go',\n",
    "        'Lineout': 'lo',\n",
    "        'Bunt Lineout': 'lo',\n",
    "        'Flyout': 'fo',\n",
    "        'Sac Fly': 'fo',\n",
    "        'Sac Fly Double Play': 'fo',\n",
    "        'Pop Out': 'po',\n",
    "        'Bunt Pop Out': 'po',\n",
    "        'Hit By Pitch': 'hbp',\n",
    "        'Walk': 'bb',\n",
    "        'Intent Walk': 'bb',\n",
    "        'Single': 'b1',\n",
    "        'Double': 'b2',\n",
    "        'Triple': 'b3',\n",
    "        'Home Run': 'hr'\n",
    "    }\n",
    "\n",
    "    df['eventsModel'] = df['event'].map(event_mapping).fillna('Cut')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b97c232-0f40-4761-93a9-6e9b7bf93f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This turns several variables, including events, venues, hands, and bases into dummies\n",
    "def create_dummies(df):    \n",
    "    # Events\n",
    "    event_dummies = pd.get_dummies(df['eventsModel'])\n",
    "    # Venues\n",
    "    venue_dummies = pd.get_dummies(df['venue_id'], prefix='venue')\n",
    "    # Hands\n",
    "    pitcher_dummies = pd.get_dummies(df['pitchHand'], prefix='p')\n",
    "    batter_dummies = pd.get_dummies(df['batSide'], prefix='b')\n",
    "    # Years\n",
    "    df['year'] = df['game_date'].str[:4]\n",
    "    year_dummies = pd.get_dummies(df['year'], prefix='year')\n",
    "    \n",
    "    # Create lists of dummies\n",
    "    venue_list = venue_dummies.columns.tolist()\n",
    "    year_list = year_dummies.columns.tolist()\n",
    "    dummy_list = venue_list + year_list\n",
    "    \n",
    "    # Add dummies to dataframe\n",
    "    df = pd.concat([df, event_dummies, venue_dummies, pitcher_dummies, batter_dummies, year_dummies], axis=1)\n",
    "    \n",
    "    # Create compatible date variable\n",
    "    df['date'] = df['game_date'].str.replace('-', '')\n",
    "    \n",
    "    # Convert to numeric for sorting\n",
    "    df['date'] = df['date'].astype('int')\n",
    "    df['gamePk'] = df['gamePk'].astype('int')\n",
    "    df['atBatIndex'] = df['atBatIndex'].astype('int')\n",
    "    \n",
    "    # Sort\n",
    "    df.sort_values(['date', 'gamePk', 'atBatIndex'], ascending=True, inplace=True)\n",
    "    \n",
    "    # Create dummy for runners on base\n",
    "    df['preOnFirst'] = df.groupby(['gamePk', 'inning', 'halfInning'])['postOnFirst'].shift(1)\n",
    "    df['preOnSecond'] = df.groupby(['gamePk', 'inning', 'halfInning'])['postOnSecond'].shift(1)\n",
    "    df['preOnThird'] = df.groupby(['gamePk', 'inning', 'halfInning'])['postOnThird'].shift(1)\n",
    "    \n",
    "    df['onFirst'] = df['preOnFirst'].apply(lambda x: 1 if isinstance(x, str) and 'id' in x else 0)\n",
    "    df['onSecond'] = df['preOnSecond'].apply(lambda x: 1 if isinstance(x, str) and 'id' in x else 0)\n",
    "    df['onThird'] = df['preOnThird'].apply(lambda x: 1 if isinstance(x, str) and 'id' in x else 0)\n",
    "    \n",
    "    # Top of the inning dummy\n",
    "    df['top'] = np.where(df['halfInning'] == \"top\", 1, 0)\n",
    "    \n",
    "    # Convert to numeric\n",
    "    df['awayScore'] = df['awayScore'].astype('int')\n",
    "    df['homeScore'] = df['homeScore'].astype('int')\n",
    "    \n",
    "    # Determine score before PA\n",
    "    df['preAwayScore'] = df.groupby(['gamePk'])['awayScore'].shift(1)\n",
    "    df['preHomeScore'] = df.groupby(['gamePk'])['homeScore'].shift(1)\n",
    "    \n",
    "    # If it's the first PA, it'll be missing. \n",
    "    df['preAwayScore'] = df['preAwayScore'].fillna(0)\n",
    "    df['preHomeScore'] = df['preHomeScore'].fillna(0)\n",
    "    \n",
    "    \n",
    "    # Calculate differential\n",
    "    df['score_diff'] = np.where(df['top'] == 1, df['preAwayScore'] - df['preHomeScore'], df['preHomeScore'] - df['preAwayScore'])\n",
    "    \n",
    "    # Calculate PAs and ABs\n",
    "    df['pa'] = np.where(df['eventsModel'] != \"Cut\", 1, 0)\n",
    "    df['ab'] = df['pa'] - df['hbp'] - df['bb']           \n",
    "            \n",
    "    # Sort\n",
    "    df.sort_values(['date', 'gamePk', 'atBatIndex'], inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9086db7e-516c-4a12-9103-cb8658e9ebf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create useful Statcast variables\n",
    "def clean_statcast(df):\n",
    "    # Convert variables to numeric\n",
    "    df['launch_speed'] = pd.to_numeric(df['launch_speed'], errors='coerce')\n",
    "    df['launch_speed_angle'] = pd.to_numeric(df['launch_speed_angle'], errors='coerce')\n",
    "    df['hc_x'] = pd.to_numeric(df['hc_x'], errors='coerce')\n",
    "    df['hc_y'] = pd.to_numeric(df['hc_y'], errors='coerce')\n",
    "    \n",
    "    # Hard hit dummy\n",
    "    df['hard_hit'] = (df['launch_speed'] >= 95).astype('int')\n",
    "    \n",
    "    # Barrel dummy\n",
    "    df['barrel'] = (df['launch_speed_angle'] == 6).astype('int')\n",
    "\n",
    "    # Spray \n",
    "    df['spray_angle'] = np.arctan((df['hc_x'] - 125.42) / (198.27 - df['hc_y'])) * 180 / np.pi * 0.75\n",
    "    df['to_left'] = (df['spray_angle'] < -15).astype('int')\n",
    "    df['to_middle'] = ((df['spray_angle'] >= -15) & (df['spray_angle'] <= 15)).astype('int')\n",
    "    df['to_right'] = (df['spray_angle'] > 15).astype('int')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29d37a98-4db1-4a18-9597-59b3e8d40b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in park factors to adjust stats\n",
    "def read_park_factors():\n",
    "    # Read in park factors\n",
    "    park_factors = pd.read_sql_table('Statcast Park Factors', engine)\n",
    "    \n",
    "    # Clean\n",
    "    park_factors['Team'] = park_factors['Team'].str.strip()\n",
    "  \n",
    "    # Read in team_map \n",
    "    team_map = pd.read_sql_table('Team Map', engine)\n",
    "    \n",
    "    # Merge with team map to get venue ID\n",
    "    park_factors = park_factors.merge(team_map[['FANGRAPHSTEAM', 'VENUE_ID']], left_on='Team', right_on='FANGRAPHSTEAM', how='inner')\n",
    "    park_factors.rename(columns={'VENUE_ID':'venue_id'}, inplace=True)\n",
    "    \n",
    "    # Keep relevant variables\n",
    "    park_factors = park_factors[['venue_id', 'batSide', 'Park Factor', '1B', '2B', '3B', 'HR', 'BB', 'SO']]\n",
    "    \n",
    "    # Convert to mean of 1, not 100\n",
    "    factor_list = ['Park Factor', '1B', '2B', '3B', 'HR', 'BB', 'SO']\n",
    "    for factor in factor_list:\n",
    "        park_factors[factor] = park_factors[factor].astype('int') / 100\n",
    "        \n",
    "    # Convert to numeric\n",
    "    park_factors['venue_id'] = park_factors['venue_id'].astype('str')\n",
    "    \n",
    "    # Sort\n",
    "    park_factors.sort_values(['venue_id', 'batSide'], inplace=True)\n",
    "    \n",
    "    return park_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6ff24513-4698-4e5a-a3e7-0abefef16ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust for park factors\n",
    "def park_adjustments(df):   \n",
    "    # Read in park factors\n",
    "    park_factors = read_park_factors()\n",
    "    \n",
    "    # Convert to string\n",
    "    df['venue_id'] = df['venue_id'].astype('str')\n",
    "    \n",
    "    # Merge with park factors\n",
    "    df = df.merge(park_factors, on=['venue_id', 'batSide'], how='left', indicator=True)\n",
    "    \n",
    "    # Old/other parks get all 1s\n",
    "    df[['Park Factor', '1B', '2B', '3B', 'HR', 'BB', 'SO']] = df[['Park Factor', '1B', '2B', '3B', 'HR', 'BB', 'SO']].fillna(1)\n",
    "    \n",
    "    \n",
    "    # Adjust stats by park factor\n",
    "    df['b1'] = df['b1'].astype('float') / df['1B'].astype('float')\n",
    "    df['b2'] = df['b2'].astype('float') / df['2B'].astype('float')\n",
    "    df['b3'] = df['b3'].astype('float') / df['3B'].astype('float')\n",
    "    df['hr'] = df['hr'].astype('float') / df['HR'].astype('float')\n",
    "    df['bb'] = df['bb'].astype('float') / df['BB'].astype('float')\n",
    "    df['so'] = df['so'].astype('float') / df['SO'].astype('float')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2f862055-9a96-49e2-8844-6fde8b4bb5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will return a dataframe that can eventually be used as the model input. Has pitcher vs hitter stats, specific to hand\n",
    "def rolling_pas(df, pa_num):\n",
    "    # Copy dataframe\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # Note: batter_avg_short will work even when pa_num refers to the \"long\" period. Suffix will be added in post.\n",
    "    # Rename for compatibility purposes\n",
    "    df_copy.rename(columns={'hit_distance_sc':'totalDistance', 'launch_speed':'launchSpeed'}, inplace=True)          \n",
    "            \n",
    "    # Convert to numeric and fill with 0s\n",
    "    combined_list = avg_list + max_list\n",
    "    for col in combined_list:\n",
    "        # Check if the column is not numeric\n",
    "        if not pd.api.types.is_numeric_dtype(df_copy[col]):\n",
    "            # Convert the non-numeric column to numeric and fill missing values with 0\n",
    "            df_copy[col] = pd.to_numeric(df_copy[col], errors='coerce')\n",
    "            df_copy[col] = df_copy[col].fillna(0)\n",
    "\n",
    "    # Sort\n",
    "    df_copy.sort_values(['date', 'gamePk', 'atBatIndex'], ascending=True, inplace=True)\n",
    "            \n",
    "    # Data types may vary. This makes grouping impossible. \n",
    "    df_copy['batter'] = df_copy['batter'].astype('int')\n",
    "    df_copy['pitcher'] = df_copy['pitcher'].astype('int')\n",
    "        \n",
    "    ### Batter stats \n",
    "    # Stats for which you want the average \n",
    "    df_copy[batter_avg_short] = df_copy.groupby(['batter', 'pitchHand'])[avg_list].transform(lambda x: x.shift().rolling(pa_num, min_periods=1).mean())\n",
    "    # Stats for which you want the maximum\n",
    "    df_copy[batter_max_short] = df_copy.groupby(['batter', 'pitchHand'])[max_list].transform(lambda x: x.shift().rolling(pa_num, min_periods=1).max())\n",
    "    # Stats for which you just want the sum \n",
    "    df_copy[['ab_b', 'pa_b']] = df_copy.groupby(['batter', 'pitchHand'])[['ab', 'pa']].transform(lambda x: x.shift().rolling(pa_num, min_periods=1).sum())\n",
    "                \n",
    "    ### Pitcher stats\n",
    "    # Stats for which you want the average\n",
    "    df_copy[pitcher_avg_short] = df_copy.groupby(['pitcher', 'batSide'])[avg_list].transform(lambda x: x.shift().rolling(pa_num, min_periods=1).mean())\n",
    "    # Stats for which you want the maximum\n",
    "    df_copy[pitcher_max_short] = df_copy.groupby(['pitcher', 'batSide'])[max_list].transform(lambda x: x.shift().rolling(pa_num, min_periods=1).max())\n",
    "    # Stats for which you just want the sum \n",
    "    df_copy[['ab_p', 'pa_p']] = df_copy.groupby(['pitcher', 'batSide'])[['ab', 'pa']].transform(lambda x: x.shift().rolling(pa_num, min_periods=1).sum())\n",
    "                \n",
    "    # Create imputation flags (these observations will have imputed inputs)\n",
    "    df_copy['imp_b'] = (df_copy['pa_b'] < 40).astype('int')\n",
    "    df_copy['imp_p'] = (df_copy['pa_p'] < 40).astype('int')\n",
    "\n",
    "    # Create compatible date variable\n",
    "    df_copy['date'] = df_copy['game_date'].str.replace('-', '')\n",
    "    \n",
    "    # Convert to numeric for sorting\n",
    "    df_copy['date'] = df_copy['date'].astype('int')\n",
    "    df_copy['gamePk'] = df_copy['gamePk'].astype('int')\n",
    "    df_copy['atBatIndex'] = df_copy['atBatIndex'].astype('int')\n",
    "    df_copy['batter'] = df_copy['batter'].astype('int')\n",
    "    df_copy['pitcher'] = df_copy['pitcher'].astype('int')\n",
    "    \n",
    "    \n",
    "    # Sort\n",
    "    df_copy.sort_values(['date', 'gamePk', 'atBatIndex'], ascending=True, inplace=True)\n",
    "\n",
    "    ### Advanced stats\n",
    "    # wOBA - using 2022 values throughout\n",
    "    df_copy['woba_b'] = (0.690 * df_copy['bb_b']) + (0.721 * df_copy['hbp_b']) + (0.885 * df_copy['b1_b']) + (1.262 * df_copy['b2_b']) + (1.601 * df_copy['b3_b']) + (2.070 * df_copy['hr_b'])\n",
    "    df_copy['woba_p'] = (0.690 * df_copy['bb_p']) + (0.721 * df_copy['hbp_p']) + (0.885 * df_copy['b1_p']) + (1.262 * df_copy['b2_p']) + (1.601 * df_copy['b3_p']) + (2.070 * df_copy['hr_p'])\n",
    "    \n",
    "    # Slugging\n",
    "    df_copy['slg_b'] = (1 * df_copy['b1_b']) + (2 * df_copy['b2_b']) + (3 * df_copy['b3_b']) + (4 * df_copy['hr_b'])\n",
    "    df_copy['slg_b'] = df_copy['slg_b'] / df_copy['ab_b']\n",
    "    df_copy['slg_p'] = (1 * df_copy['b1_p']) + (2 * df_copy['b2_p']) + (3 * df_copy['b3_p']) + (4 * df_copy['hr_p'])\n",
    "    df_copy['slg_p'] = df_copy['slg_p'] / df_copy['ab_p']\n",
    "\n",
    "    # OBP    \n",
    "    df_copy['obp_b'] = df_copy[['b1_b', 'b2_b', 'b3_b', 'hr_b', 'bb_b', 'hbp_b']].sum(axis=1)\n",
    "    df_copy['obp_p'] = df_copy[['b1_p', 'b2_p', 'b3_p', 'hr_p', 'bb_p', 'hbp_p']].sum(axis=1)\n",
    "    \n",
    "    # ISO\n",
    "    df_copy['iso_b'] = df_copy['b2_b'] * 1 + df_copy['b3_b'] * 2 + df_copy['hr_b'] * 3\n",
    "    df_copy['iso_p'] = df_copy['b2_p'] * 1 + df_copy['b3_p'] * 2 + df_copy['hr_p'] * 3\n",
    "\n",
    "\n",
    "        \n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c89a7cc-eadc-451c-8c41-7e34e8d01222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates model inputs\n",
    "def create_inputs(start_year, end_year, short=50, long=300):\n",
    "    # Read in raw data\n",
    "    df = dataset(engine, start_year, end_year)\n",
    "    # Clean weather\n",
    "    df2 = clean_weather(df)\n",
    "    # Create PA events \n",
    "    df3 = create_events(df2)\n",
    "    # Create dummy variables \n",
    "    df4 = create_dummies(df3)\n",
    "    # Create Statcast variables\n",
    "    df5 = clean_statcast(df4)   \n",
    "    # Adjust for park factors\n",
    "    df6 = park_adjustments(df5)\n",
    "    \n",
    "    ### Rolling stats\n",
    "    # Short\n",
    "    df_short = rolling_pas(df6, short)\n",
    "    # Long\n",
    "    df_long = rolling_pas(df6, long)\n",
    "    df_long = df_long.add_suffix(\"_long\")\n",
    "        \n",
    "    # We only need the rolling stats \n",
    "    # rolling_stats_short = batter_stats_short + pitcher_stats_short + ['pa_b', 'ab_b', 'pa_p', 'ab_p']\n",
    "    long_stats = batter_stats_long + pitcher_stats_long\n",
    "    df_long = df_long[long_stats]\n",
    "    \n",
    "    # Dataset\n",
    "    complete_dataset = pd.concat([df_short, df_long], axis=1)\n",
    "            \n",
    "    # Sort\n",
    "    complete_dataset.sort_values(['date', 'gamePk', 'atBatIndex'], ascending=True, inplace=True)\n",
    "    \n",
    "    \n",
    "    return complete_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b13a1c-9e37-45ae-8270-2d9a6e700ec6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c98a4860-ec41-4ccb-9304-193b51f782ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run \"U1. Imports.ipynb\"\n",
    "# %run \"U2. Utilities.ipynb\"\n",
    "# %run \"U3. Classes.ipynb\"\n",
    "# %run \"D3. Simulation Functions.ipynb\"\n",
    "\n",
    "# baseball_path = r'C:\\Users\\james\\Documents\\MLB\\Database'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80c2d4af-1eb8-4561-957c-6de07a5ab4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# db_path = r'C:\\Users\\james\\Documents\\MLB\\Database\\MLBDB.db'\n",
    "# engine = create_engine(f'sqlite:///{db_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "62c70f3d-b0c2-4818-9e54-c6b1666608d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = dataset(engine, 2015, 2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "814343ba-2b59-43c4-9919-35a253905fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2 = clean_weather(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "edd0e17a-128a-459d-873c-603405fcbd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df3 = create_events(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "147ff2ac-40ed-46e7-91bc-e940d81b9e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df4 = create_dummies(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0deb040f-06fb-4c8e-b347-3aa877328f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df5 = clean_statcast(df4)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1691949e-7118-4d1e-9638-6e449857fe4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df6 = park_adjustments(df5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "688a4ced-c210-401b-be54-038acd1f8e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_short = rolling_pas(df6, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "75ace51a-dd0c-4b78-9236-15fd14a7c1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_short.query(\"batterName == 'Rafael Devers'\").query('date >= 20220930').query('pitchHand == \"L\"')[['date', 'batterName', 'batter', 'pitchHand', 'venue_id', '1B', 'b1', 'b1_b', 'hr', 'hr_b']].head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2ebf58-7f5f-4d39-b43b-554b37ee2220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_short[batter_stats_short].tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35073859-3b66-459e-b2ff-3e71fbfc686a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_long = rolling_pas(df6, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "70fc179b-f481-4ca1-9c60-1cedb7fc6b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_long = df_long.add_suffix(\"_long\")\n",
    "# df_long[batter_stats_long].tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4d1852-fe94-47a5-a6d3-04679988cda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete_dataset = pd.concat([df_short, df_long], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3503c60b-ea3a-4309-8e28-731deb9cb019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete_dataset[batter_stats_short + batter_stats_long].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c90da2a-247f-4702-9b89-728f97c9a3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete_dataset[['b1_b', 'b1_b_long']].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54071ec7-74a3-44c6-ad23-354fbf7236be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_short[batter_stats_short].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4941322-0cca-4621-833f-065de7cfb014",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
